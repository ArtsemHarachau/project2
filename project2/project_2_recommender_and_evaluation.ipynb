{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alike-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arciom\\anaconda3\\envs\\rs-class-env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from livelossplot import PlotLosses\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-knitting",
   "metadata": {},
   "source": [
    "# Load the dataset for recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "victorian-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>term</th>\n",
       "      <th>length_of_stay_bucket</th>\n",
       "      <th>rate_plan</th>\n",
       "      <th>room_segment</th>\n",
       "      <th>n_people_bucket</th>\n",
       "      <th>weekend_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Easter</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = os.path.join(\"data\", \"hotel_data\")\n",
    "\n",
    "interactions_df = pd.read_csv(os.path.join(data_path, \"hotel_data_interactions_df.csv\"), index_col=0)\n",
    "\n",
    "base_item_features = ['term', 'length_of_stay_bucket', 'rate_plan', 'room_segment', 'n_people_bucket', 'weekend_stay']\n",
    "\n",
    "column_values_dict = {\n",
    "    'term': ['WinterVacation', 'Easter', 'OffSeason', 'HighSeason', 'LowSeason', 'MayLongWeekend', 'NewYear', 'Christmas'],\n",
    "    'length_of_stay_bucket': ['[0-1]', '[2-3]', '[4-7]', '[8-inf]'],\n",
    "    'rate_plan': ['Standard', 'Nonref'],\n",
    "    'room_segment': ['[0-160]', '[160-260]', '[260-360]', '[360-500]', '[500-900]'],\n",
    "    'n_people_bucket': ['[1-1]', '[2-2]', '[3-4]', '[5-inf]'],\n",
    "    'weekend_stay': ['True', 'False']\n",
    "}\n",
    "\n",
    "interactions_df.loc[:, 'term'] = pd.Categorical(\n",
    "    interactions_df['term'], categories=column_values_dict['term'])\n",
    "interactions_df.loc[:, 'length_of_stay_bucket'] = pd.Categorical(\n",
    "    interactions_df['length_of_stay_bucket'], categories=column_values_dict['length_of_stay_bucket'])\n",
    "interactions_df.loc[:, 'rate_plan'] = pd.Categorical(\n",
    "    interactions_df['rate_plan'], categories=column_values_dict['rate_plan'])\n",
    "interactions_df.loc[:, 'room_segment'] = pd.Categorical(\n",
    "    interactions_df['room_segment'], categories=column_values_dict['room_segment'])\n",
    "interactions_df.loc[:, 'n_people_bucket'] = pd.Categorical(\n",
    "    interactions_df['n_people_bucket'], categories=column_values_dict['n_people_bucket'])\n",
    "interactions_df.loc[:, 'weekend_stay'] = interactions_df['weekend_stay'].astype('str')\n",
    "interactions_df.loc[:, 'weekend_stay'] = pd.Categorical(\n",
    "    interactions_df['weekend_stay'], categories=column_values_dict['weekend_stay'])\n",
    "\n",
    "display(HTML(interactions_df.head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-third",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical user features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based user features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "variable-jaguar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_term_WinterVacation', 'user_term_Easter', 'user_term_OffSeason', 'user_term_HighSeason', 'user_term_LowSeason', 'user_term_MayLongWeekend', 'user_term_NewYear', 'user_term_Christmas', 'user_length_of_stay_bucket_[0-1]', 'user_length_of_stay_bucket_[2-3]', 'user_length_of_stay_bucket_[4-7]', 'user_length_of_stay_bucket_[8-inf]', 'user_rate_plan_Standard', 'user_rate_plan_Nonref', 'user_room_segment_[0-160]', 'user_room_segment_[160-260]', 'user_room_segment_[260-360]', 'user_room_segment_[360-500]', 'user_room_segment_[500-900]', 'user_n_people_bucket_[1-1]', 'user_n_people_bucket_[2-2]', 'user_n_people_bucket_[3-4]', 'user_n_people_bucket_[5-inf]', 'user_weekend_stay_True', 'user_weekend_stay_False']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_term_WinterVacation</th>\n",
       "      <th>user_term_Easter</th>\n",
       "      <th>user_term_OffSeason</th>\n",
       "      <th>user_term_HighSeason</th>\n",
       "      <th>user_term_LowSeason</th>\n",
       "      <th>user_term_MayLongWeekend</th>\n",
       "      <th>user_term_NewYear</th>\n",
       "      <th>user_term_Christmas</th>\n",
       "      <th>user_length_of_stay_bucket_[0-1]</th>\n",
       "      <th>user_length_of_stay_bucket_[2-3]</th>\n",
       "      <th>user_length_of_stay_bucket_[4-7]</th>\n",
       "      <th>user_length_of_stay_bucket_[8-inf]</th>\n",
       "      <th>user_rate_plan_Standard</th>\n",
       "      <th>user_rate_plan_Nonref</th>\n",
       "      <th>user_room_segment_[0-160]</th>\n",
       "      <th>user_room_segment_[160-260]</th>\n",
       "      <th>user_room_segment_[260-360]</th>\n",
       "      <th>user_room_segment_[360-500]</th>\n",
       "      <th>user_room_segment_[500-900]</th>\n",
       "      <th>user_n_people_bucket_[1-1]</th>\n",
       "      <th>user_n_people_bucket_[2-2]</th>\n",
       "      <th>user_n_people_bucket_[3-4]</th>\n",
       "      <th>user_n_people_bucket_[5-inf]</th>\n",
       "      <th>user_weekend_stay_True</th>\n",
       "      <th>user_weekend_stay_False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>50</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>96</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>706</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.132530</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.273810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>1736</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>7779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def n_to_p(l):\n",
    "    n = sum(l)\n",
    "    return [x / n for x in l] if n > 0 else l\n",
    "\n",
    "def calculate_p(x, values):\n",
    "    counts = [0]*len(values)\n",
    "    #print(counts)\n",
    "    ####\n",
    "    #newlist = [elem for elem in x if np.isnan(elem) == False]\n",
    "    #x = newlist\n",
    "    #print(x)\n",
    "    #print(values)\n",
    "    for v in x:\n",
    "#         print(values.index(v))\n",
    "        if v in values:\n",
    "            counts[values.index(v)] += 1\n",
    "#         counts[values.index(v)] += 1\n",
    "\n",
    "    return n_to_p(counts)\n",
    "\n",
    "def prepare_users_df(interactions_df):\n",
    "\n",
    "    users_df = interactions_df.loc[:, [\"user_id\"]]\n",
    "    users_df = users_df.groupby(\"user_id\").first().reset_index(drop=False)\n",
    "    \n",
    "    user_features = []\n",
    "\n",
    "    for column in base_item_features:\n",
    "\n",
    "        column_values = column_values_dict[column]\n",
    "        df = interactions_df.loc[:, ['user_id', column]]\n",
    "        df = df.groupby('user_id').aggregate(lambda x: list(x)).reset_index(drop=False)\n",
    "\n",
    "        def calc_p(x):\n",
    "            return calculate_p(x, column_values)\n",
    "\n",
    "        df.loc[:, column] = df[column].apply(lambda x: calc_p(x))\n",
    "\n",
    "        p_columns = []\n",
    "        for i in range(len(column_values)):\n",
    "            p_columns.append(\"user_\" + column + \"_\" + column_values[i])\n",
    "            df.loc[:, p_columns[i]] = df[column].apply(lambda x: x[i])\n",
    "            user_features.append(p_columns[i])\n",
    "\n",
    "        users_df = pd.merge(users_df, df.loc[:, ['user_id'] + p_columns], on=[\"user_id\"])\n",
    "    \n",
    "    return users_df, user_features\n",
    "    \n",
    "\n",
    "users_df, user_features = prepare_users_df(interactions_df)\n",
    "\n",
    "print(user_features)\n",
    "\n",
    "display(HTML(users_df.loc[users_df['user_id'].isin([706, 1736, 7779, 96, 1, 50, 115])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-keyboard",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical item features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based item features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formal-munich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['term_WinterVacation', 'term_Easter', 'term_OffSeason', 'term_HighSeason', 'term_LowSeason', 'term_MayLongWeekend', 'term_NewYear', 'term_Christmas', 'length_of_stay_bucket_[0-1]', 'length_of_stay_bucket_[2-3]', 'length_of_stay_bucket_[4-7]', 'length_of_stay_bucket_[8-inf]', 'rate_plan_Standard', 'rate_plan_Nonref', 'room_segment_[0-160]', 'room_segment_[160-260]', 'room_segment_[260-360]', 'room_segment_[360-500]', 'room_segment_[500-900]', 'n_people_bucket_[1-1]', 'n_people_bucket_[2-2]', 'n_people_bucket_[3-4]', 'n_people_bucket_[5-inf]', 'weekend_stay_True', 'weekend_stay_False']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>term_WinterVacation</th>\n",
       "      <th>term_Easter</th>\n",
       "      <th>term_OffSeason</th>\n",
       "      <th>term_HighSeason</th>\n",
       "      <th>term_LowSeason</th>\n",
       "      <th>term_MayLongWeekend</th>\n",
       "      <th>term_NewYear</th>\n",
       "      <th>term_Christmas</th>\n",
       "      <th>length_of_stay_bucket_[0-1]</th>\n",
       "      <th>length_of_stay_bucket_[2-3]</th>\n",
       "      <th>length_of_stay_bucket_[4-7]</th>\n",
       "      <th>length_of_stay_bucket_[8-inf]</th>\n",
       "      <th>rate_plan_Standard</th>\n",
       "      <th>rate_plan_Nonref</th>\n",
       "      <th>room_segment_[0-160]</th>\n",
       "      <th>room_segment_[160-260]</th>\n",
       "      <th>room_segment_[260-360]</th>\n",
       "      <th>room_segment_[360-500]</th>\n",
       "      <th>room_segment_[500-900]</th>\n",
       "      <th>n_people_bucket_[1-1]</th>\n",
       "      <th>n_people_bucket_[2-2]</th>\n",
       "      <th>n_people_bucket_[3-4]</th>\n",
       "      <th>n_people_bucket_[5-inf]</th>\n",
       "      <th>weekend_stay_True</th>\n",
       "      <th>weekend_stay_False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_items_to_onehot(df):\n",
    "    one_hot = pd.get_dummies(df.loc[:, base_item_features])\n",
    "    df = df.drop(base_item_features, axis = 1)\n",
    "    df = df.join(one_hot)\n",
    "    \n",
    "    return df, list(one_hot.columns)\n",
    "\n",
    "def prepare_items_df(interactions_df):\n",
    "    items_df = interactions_df.loc[:, [\"item_id\"] + base_item_features].drop_duplicates()\n",
    "    \n",
    "    items_df, item_features = map_items_to_onehot(items_df)\n",
    "    \n",
    "    return items_df, item_features\n",
    "\n",
    "\n",
    "items_df, item_features = prepare_items_df(interactions_df)\n",
    "\n",
    "print(item_features)\n",
    "\n",
    "display(HTML(items_df.loc[items_df['item_id'].isin([0, 1, 2, 3, 4, 5, 6])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-imaging",
   "metadata": {},
   "source": [
    "# Neural network recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Code a recommender based on a neural network model. You are free to choose any network architecture you find appropriate. The network can use the interaction vectors for users and items, embeddings of users and items, as well as user and item features (you can use the features you developed in the first project).\n",
    "\n",
    "Remember to keep control over randomness - in the init method add the seed as a parameter and initialize the random seed generator with that seed (both for numpy and pytorch):\n",
    "\n",
    "```python\n",
    "self.seed = seed\n",
    "self.rng = np.random.RandomState(seed=seed)\n",
    "```\n",
    "in the network model:\n",
    "```python\n",
    "self.seed = torch.manual_seed(seed)\n",
    "```\n",
    "\n",
    "You are encouraged to experiment with:\n",
    "  - the number of layers in the network, the number of neurons and different activation functions,\n",
    "  - different optimizers and their parameters,\n",
    "  - batch size and the number of epochs,\n",
    "  - embedding layers,\n",
    "  - content-based features of both users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unlike-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.recommender import Recommender\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class NNRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Linear recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5):\n",
    "        \"\"\"\n",
    "        Initialize recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.n_neg_per_pos = n_neg_per_pos\n",
    "        \n",
    "        self.recommender_df = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        self.users_df = None\n",
    "        self.user_features = None\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "        ##\n",
    "        torch.manual_seed(seed)\n",
    "        ##\n",
    "        \n",
    "        # You can add more arguments if needed\n",
    "        # <<<Write your code here>>>\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        interactions_df = interactions_df.copy()\n",
    "        \n",
    "        # Prepare users_df and items_df \n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        users_df, user_features = prepare_users_df(interactions_df)\n",
    "        \n",
    "        self.users_df = users_df\n",
    "        self.user_features = user_features\n",
    "        \n",
    "        items_df, item_features = prepare_items_df(interactions_df)\n",
    "        items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "        \n",
    "        # Generate negative interactions\n",
    "        \n",
    "        # <<<Write your code here>>>\n",
    "        \n",
    "        negative_interactions = []\n",
    "        \n",
    "        \n",
    "        ##\n",
    "        min_item_id = interactions_df['item_id'].min()\n",
    "        max_item_id = interactions_df['item_id'].max()\n",
    "        \n",
    "        dict_interactions_df = interactions_df.to_dict('records')\n",
    "        for row in dict_interactions_df:\n",
    "            #filter on user_id\n",
    "            filtered_df_on_user_id = interactions_df[interactions_df.user_id.isin([row['user_id']])]\n",
    "            \n",
    "            #find five negative interactions\n",
    "            nr_of_neg_interactions = 0\n",
    "            while True:\n",
    "                if nr_of_neg_interactions == 5:\n",
    "                    break\n",
    "                \n",
    "                rand_item_id = np.random.randint(min_item_id, max_item_id)\n",
    "                if not (filtered_df_on_user_id['item_id'].values == [rand_item_id]).any():\n",
    "                    negative_interactions.append((row['user_id'], rand_item_id, 0))\n",
    "                    nr_of_neg_interactions += 1\n",
    "        \n",
    "        #generator of negative interactions is taken about 11-18 seconds\n",
    "        ##\n",
    "        \n",
    "        \n",
    "        \n",
    "        interactions_df = pd.concat(\n",
    "            [interactions_df, pd.DataFrame(negative_interactions, columns=['user_id', 'item_id', 'interacted'])])\n",
    "        \n",
    "        # Merge user and item features\n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, users_df, on=['user_id'])\n",
    "        interactions_df = pd.merge(interactions_df, items_df, on=['item_id'])\n",
    "        \n",
    "        #change NAN with fillna\n",
    "        interactions_df['interacted'] = interactions_df['interacted'].fillna(0).astype(float)\n",
    "        #\n",
    "\n",
    "        # Initialize the neural network model\n",
    "        \n",
    "        # <<<Write your code here>>>\n",
    "        ##\n",
    "        self.model = NetworkModel(len(user_features) + len(item_features), self.seed)\n",
    "        self.model.train()\n",
    "        criterion = nn.MSELoss()#nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        ##\n",
    "        \n",
    "        # Train the model using an optimizer\n",
    "        \n",
    "        # <<<Write your code here>>>\n",
    "        \n",
    "        \n",
    "#         ##matrix factorization\n",
    "#         users_id_list = interactions_df['user_id'].tolist()\n",
    "#         items_id_list = interactions_df['item_id'].tolist()\n",
    "#         interacted_list = interactions_df['interacted'].tolist()\n",
    "        \n",
    "        \n",
    "#         self.model = MatrixFactorization(self.seed, len(users_id_list), len(items_id_list), n_factors=8)\n",
    "#         loss_fn = nn.MSELoss() \n",
    "#         optimizer = torch.optim.SparseAdam(self.model.parameters(), lr=0.01, eps=1e-08)#torch.optim.Adam(self.model.parameters(), lr=0.01)#torch.optim.SGD(self.model.parameters(), lr=1e-6)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         data = []\n",
    "        \n",
    "        \n",
    "#         for index in range(len(users_id_list)):\n",
    "#             data.append((torch.tensor(users_id_list[index]), torch.tensor(items_id_list[index]), torch.tensor(interacted_list[index])))\n",
    "        \n",
    "#         n_epochs = 100\n",
    "#         for epoch in range(n_epochs):\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             for index in range(len(data)):\n",
    "#                 prediction = self.model(Variable(data[index][0]), Variable(data[index][1]))\n",
    "#                 loss = loss_fn(prediction, Variable(data[index][2]))\n",
    "                \n",
    "#                 # backpropagate\n",
    "#                 loss.backward()\n",
    "\n",
    "#                 # update weights\n",
    "#                 optimizer.step()\n",
    "                \n",
    "#         ##\n",
    "        \n",
    "        \n",
    "        ##embedding\n",
    "        \n",
    "#         list_of_users_ids = sorted(interactions_df['user_id'].unique())\n",
    "#         user_ids = []\n",
    "        \n",
    "#         for index in range(len(list_of_users_ids)):\n",
    "#             user_ids.append(torch.tensor(list_of_users_ids[index]))\n",
    "        \n",
    "# #         user_ids = [torch.tensor(0), torch.tensor(1), torch.tensor(2)]\n",
    "#         list_of_items_ids = sorted(interactions_df['item_id'].unique())\n",
    "#         items = []\n",
    "        \n",
    "#         for index in range(len(list_of_items_ids)):\n",
    "#             item_tensor = torch.rand(8)\n",
    "#             items.append(item_tensor)\n",
    "# #         items = [torch.tensor([0.6, 0.4, -0.2]), torch.tensor([-0.7, 0.8, -0.7]), torch.tensor([0.8, -0.75, 0.9])]\n",
    "# #         responses = [1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
    "#         data = [(user_ids[user_id], items[item_id]) for user_id in range(len(list_of_users_ids)) for item_id in range(len(list_of_items_ids))]\n",
    "\n",
    "#         self.model = EmbeddingNetworkModel(seed=6789, num_users=len(list_of_users_ids)*2, num_items=len(list_of_items_ids))\n",
    "\n",
    "#         optimizer = optim.SGD(self.model.parameters(), lr=0.1)\n",
    "\n",
    "#         losses = []\n",
    "#         n_epochs = 100\n",
    "#         for epoch in range(n_epochs):\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "    \n",
    "#             for i in range(len(data)):\n",
    "#                 user_id = data[i][0]\n",
    "#                 item_repr = data[i][1]\n",
    "# #                 print(user_id)\n",
    "# #                 print(item_repr)\n",
    "        \n",
    "#                 y = self.model((user_id, item_repr))\n",
    "# #                 if i == 0:\n",
    "# #                     loss = torch.pow(y - responses[i], 2)\n",
    "# #                 else:\n",
    "# #                     loss += torch.pow(y - responses[i], 2)\n",
    "            \n",
    "# #             for param in embedding_nn.parameters():\n",
    "# #                 loss += 1 / 5 * torch.norm(param)\n",
    "    \n",
    "#         loss.backward()\n",
    "# #         losses.append(loss.item())\n",
    "#         optimizer.step()\n",
    "#         ##\n",
    "        \n",
    "        \n",
    "        ##\n",
    "        \n",
    "        x = interactions_df.loc[:, user_features + item_features]#.values\n",
    "        \n",
    "        \n",
    "#         ##\n",
    "        x_data_tensor = torch.zeros((x.shape[1], x.shape[0]))\n",
    "        columns_name_in_x = x.columns.tolist()\n",
    "        for column_name in columns_name_in_x:\n",
    "            column_data_tensor = torch.tensor([x[column_name].tolist()])\n",
    "            x_data_tensor = torch.cat((x_data_tensor, column_data_tensor), dim=0)\n",
    "                \n",
    "        x_data_tensor = x_data_tensor[x.shape[1]:, :]\n",
    "        \n",
    "        x_data_tensor = torch.transpose(x_data_tensor, 0, 1)\n",
    "\n",
    "        y = interactions_df['interacted'].values\n",
    "    \n",
    "        y_data_tensor = torch.tensor([y.tolist()])\n",
    "        y_data_tensor = y_data_tensor.reshape([y_data_tensor.shape[1], y_data_tensor.shape[0]])\n",
    "        \n",
    "#         X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "#         X_train = torch.FloatTensor(X_train)\n",
    "#         X_test = torch.FloatTensor(X_test)\n",
    "#         y_train = torch.FloatTensor(y_train)\n",
    "#         y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "        \n",
    "        \n",
    "        epochs = 1000\n",
    "#         loss_arr = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            y_hat = (self.model.forward(x_data_tensor))\n",
    "#             y_hat = (self.model.forward(X_train)).squeeze()\n",
    "#             display(y_hat.shape)\n",
    "#             display(y_hat)\n",
    "            loss = criterion(y_hat, y_data_tensor)\n",
    "#             loss = criterion(y_hat, y_train)\n",
    "#             loss_arr.append(loss)\n",
    "            \n",
    "#             if i % 10 == 0:\n",
    "#                 print(f'Epoch: {i} Loss: {loss}')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Clean previous recommendations (iloc could be used alternatively)\n",
    "        self.recommender_df = self.recommender_df[:0]\n",
    "        \n",
    "        # Prepare users_df and items_df\n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        users_df = users_df.loc[:, 'user_id']\n",
    "        users_df = pd.merge(users_df, self.users_df, on=['user_id'], how='left').fillna(0)\n",
    "        \n",
    "        items_df, item_features = prepare_items_df(items_df)\n",
    "#         items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "\n",
    "        \n",
    "        ##tensor from items data\n",
    "        items_data_tensor = torch.zeros((items_df.shape[1] - 1, items_df.shape[0]))\n",
    "        columns_name_in_items_df = items_df.columns.tolist()\n",
    "        for column_name in columns_name_in_items_df:\n",
    "            if column_name != 'item_id':\n",
    "                column_data_tensor = torch.tensor([items_df[column_name].tolist()])\n",
    "                items_data_tensor = torch.cat((items_data_tensor, column_data_tensor), dim=0)\n",
    "                \n",
    "        items_data_tensor = items_data_tensor[25:, :]\n",
    "        \n",
    "        items_data_tensor = torch.transpose(items_data_tensor, 0, 1)\n",
    "\n",
    "        \n",
    "        # Score the items\n",
    "    \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            \n",
    "            # Calculate the score for the user and every item in items_df\n",
    "            # <<<Write your code here>>>\n",
    "            ##\n",
    "            only_one_user_df = users_df.loc[users_df['user_id'].isin([user['user_id']])]\n",
    "            \n",
    "            ##tensor from users data\n",
    "            users_data_tensor = torch.zeros((only_one_user_df.shape[1] - 1, only_one_user_df.shape[0]))\n",
    "            columns_name_in_users_df = only_one_user_df.columns.tolist()\n",
    "            for column_name in columns_name_in_users_df:\n",
    "                if column_name != 'user_id':\n",
    "                    column_data_tensor = torch.tensor([only_one_user_df[column_name].tolist()])\n",
    "                    users_data_tensor = torch.cat((users_data_tensor, column_data_tensor), dim=0)\n",
    "                \n",
    "            users_data_tensor = users_data_tensor[25:, :]\n",
    "        \n",
    "            users_data_tensor = torch.transpose(users_data_tensor, 0, 1)\n",
    "            \n",
    "            ##\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ##\n",
    "        \n",
    "            ##concatenate users tensor and items tensor to scores tensor\n",
    "            tensor_for_scores = torch.zeros((1, users_data_tensor.shape[1] + items_data_tensor.shape[1]))\n",
    "\n",
    "            for index_item in range(items_data_tensor.shape[0]):\n",
    "                for index_user in range(users_data_tensor.shape[0]):\n",
    "                    tensor_cross_join = torch.cat((users_data_tensor[index_user].reshape([1, users_data_tensor.shape[1]]), items_data_tensor[index_item].reshape([1, items_data_tensor.shape[1]])), dim=1)\n",
    "                    tensor_for_scores = torch.cat((tensor_for_scores, tensor_cross_join), dim=0)\n",
    "            \n",
    "            tensor_for_scores = tensor_for_scores[1:, :]\n",
    "            \n",
    "            \n",
    "            scores = []\n",
    "            \n",
    "#             data_for_scores = torch.tensor(list(zip([user['user_id']]*len(list_of_items_id), list_of_items_id)))#.to(self.device)\n",
    "            scores = self.model(tensor_for_scores).flatten().detach().cpu().numpy()\n",
    "            \n",
    "            \n",
    "\n",
    "            chosen_ids = np.argsort(-scores)[:n_recommendations]\n",
    "            \n",
    "            recommendations = []\n",
    "            for item_id in chosen_ids:\n",
    "                recommendations.append(\n",
    "                    {\n",
    "                        'user_id': user['user_id'],\n",
    "                        'item_id': item_id,\n",
    "                        'score': scores[item_id]\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            user_recommendations = pd.DataFrame(recommendations)\n",
    "\n",
    "            self.recommender_df = pd.concat([self.recommender_df, user_recommendations])\n",
    "\n",
    "        return self.recommender_df\n",
    "    \n",
    "    \n",
    "class NetworkModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear regression recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feat_for_layer1, seed):\n",
    "        super().__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.layer1 = nn.Linear(in_features=50, out_features=100)#change in_feat100,60,200\n",
    "#         self.layer2 = nn.Linear(in_features=200, out_features=25)#20,5,25\n",
    "        self.output = nn.Linear(in_features=100, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "#         x = F.relu(self.layer2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EmbeddingNetworkModel(nn.Module):\n",
    "    def __init__(self, seed, num_users, num_items):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "\n",
    "        self.embedding = nn.Embedding(num_users, 8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        user_id = x[0]\n",
    "        item_repr = x[1]\n",
    "        y = self.embedding(user_id) * item_repr\n",
    "        y = torch.sum(y)\n",
    "        y = torch.sigmoid(y)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    \n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, seed, n_users, n_items, n_factors=8):\n",
    "        super().__init__()\n",
    "    # create user embeddings\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        \n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors,\n",
    "                                               sparse=True)\n",
    "    # create item embeddings\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors,\n",
    "                                               sparse=True)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # matrix multiplication\n",
    "        return (self.user_factors(user)*self.item_factors(item)).sum(0)\n",
    "\n",
    "    def predict(self, user, item):\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-relative",
   "metadata": {},
   "source": [
    "# Quick test of the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greatest-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = interactions_df.loc[:, ['item_id'] + base_item_features].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit method\n",
    "nn_recommender = NNRecommender()\n",
    "\n",
    "####\n",
    "#users_df = interactions_df.loc[:, [\"user_id\"]]\n",
    "#users_df = users_df.groupby(\"user_id\").first().reset_index(drop=False)\n",
    "\n",
    "nn_recommender.fit(interactions_df, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "digital-consolidation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "      <th>length_of_stay_bucket</th>\n",
       "      <th>rate_plan</th>\n",
       "      <th>room_segment</th>\n",
       "      <th>n_people_bucket</th>\n",
       "      <th>weekend_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>620</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>178</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>Easter</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>239</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>336</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>387</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>347</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>634</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>374</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>409</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>488</td>\n",
       "      <td>0.00144</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>349</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>239</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>615</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>686</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>NewYear</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>674</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>707</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>307</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>640</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>387</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>722</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>634</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>239</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.0</td>\n",
       "      <td>349</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>485</td>\n",
       "      <td>0.00223</td>\n",
       "      <td>NewYear</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.0</td>\n",
       "      <td>320</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.0</td>\n",
       "      <td>720</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.0</td>\n",
       "      <td>546</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>497</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>150.0</td>\n",
       "      <td>480</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>NewYear</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>150.0</td>\n",
       "      <td>557</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>150.0</td>\n",
       "      <td>459</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>NewYear</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>150.0</td>\n",
       "      <td>539</td>\n",
       "      <td>0.00511</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>150.0</td>\n",
       "      <td>405</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>NewYear</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>150.0</td>\n",
       "      <td>540</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>150.0</td>\n",
       "      <td>682</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>NewYear</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>150.0</td>\n",
       "      <td>452</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>NewYear</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>150.0</td>\n",
       "      <td>373</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>NewYear</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>150.0</td>\n",
       "      <td>471</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>NewYear</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>396</td>\n",
       "      <td>0.013493</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>222</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>MayLongWeekend</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>623</td>\n",
       "      <td>0.01311</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>736</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>340</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>282</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>417</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>722</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[360-500]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>638</td>\n",
       "      <td>0.010303</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>320</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recommender method\n",
    "\n",
    "recommendations = nn_recommender.recommend(pd.DataFrame([[1], [2], [3], [150], [35000]], columns=['user_id']), items_df, 10)\n",
    "# recommendations = nn_recommender.recommend(pd.DataFrame([[1], [2], [3], [150], [35000]], columns=['user_id']), interactions_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, items_df, on='item_id', how='left')\n",
    "display(HTML(recommendations.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-eleven",
   "metadata": {},
   "source": [
    "# Tuning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "strange-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_and_testing.testing import evaluate_train_test_split_implicit\n",
    "\n",
    "seed = 6789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "stable-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import traceback\n",
    "\n",
    "def tune_recommender(recommender_class, interactions_df, items_df, \n",
    "                     param_space, max_evals=1, show_progressbar=True, seed=6789):\n",
    "    # Split into train_validation and test sets\n",
    "\n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    train_validation = interactions_df.iloc[shuffle[:split_index]]\n",
    "    test = interactions_df.iloc[shuffle[split_index:]]\n",
    "\n",
    "    # Tune\n",
    "\n",
    "    def loss(tuned_params):\n",
    "        recommender = recommender_class(seed=seed, **tuned_params)\n",
    "        hr1, hr3, hr5, hr10, ndcg1, ndcg3, ndcg5, ndcg10 = evaluate_train_test_split_implicit(\n",
    "            recommender, train_validation, items_df, seed=seed)\n",
    "        return -hr10\n",
    "\n",
    "    n_tries = 1\n",
    "    succeded = False\n",
    "    try_id = 0\n",
    "    while not succeded and try_id < n_tries:\n",
    "        try:\n",
    "            trials = Trials()\n",
    "            best_param_set = fmin(loss, space=param_space, algo=tpe.suggest, \n",
    "                                  max_evals=max_evals, show_progressbar=show_progressbar, trials=trials, verbose=True)\n",
    "            succeded = True\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            try_id += 1\n",
    "            \n",
    "    if not succeded:\n",
    "        return None\n",
    "        \n",
    "    # Validate\n",
    "    \n",
    "    recommender = recommender_class(seed=seed, **best_param_set)\n",
    "\n",
    "    results = [[recommender_class.__name__] + list(evaluate_train_test_split_implicit(\n",
    "        recommender, {'train': train_validation, 'test': test}, items_df, seed=seed))]\n",
    "\n",
    "    results = pd.DataFrame(results, \n",
    "                           columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "    display(HTML(results.to_html()))\n",
    "    \n",
    "    return best_param_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-switzerland",
   "metadata": {},
   "source": [
    "## Tuning of the recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Tune your model using the code below. You only need to put the class name of your recommender and choose an appropriate parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "obvious-astrology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [27:48<00:00, 166.87s/trial, best loss: -0.0016927634363097758]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'n_neg_per_pos': 10.0}\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "    'n_neg_per_pos': hp.quniform('n_neg_per_pos', 1, 10, 1)\n",
    "}\n",
    "\n",
    "best_param_set = tune_recommender(NNRecommender, interactions_df, items_df,\n",
    "                                  param_space, max_evals=10, show_progressbar=True, seed=seed)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-strap",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Run the final evaluation of your recommender and present its results against the Amazon and Netflix recommenders' results. You just need to give the class name of your recommender and its tuned parameters below.\n",
    "\n",
    "It's optional, but for better effect you can include here the results from all recommenders created during in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "given-homework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70204, 59)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(70204, 50)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_recommender = NNRecommender(n_neg_per_pos=1)  # Initialize your recommender here\n",
    "\n",
    "# Give the name of your recommender in the line below\n",
    "nn_tts_results = [['NNRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    nn_recommender, interactions_df, items_df))]\n",
    "\n",
    "nn_tts_results = pd.DataFrame(\n",
    "    nn_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(nn_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "suited-nomination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmazonRecommender</td>\n",
       "      <td>0.046843</td>\n",
       "      <td>0.126273</td>\n",
       "      <td>0.173456</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.046843</td>\n",
       "      <td>0.092202</td>\n",
       "      <td>0.111853</td>\n",
       "      <td>0.135876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from recommenders.amazon_recommender import AmazonRecommender\n",
    "\n",
    "amazon_recommender = AmazonRecommender()\n",
    "\n",
    "amazon_tts_results = [['AmazonRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    amazon_recommender, interactions_df, items_df))]\n",
    "\n",
    "amazon_tts_results = pd.DataFrame(\n",
    "    amazon_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(amazon_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "conservative-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    0.068, max:    0.233, cur:    0.068)\n",
      "\tvalidation       \t (min:    0.182, max:    0.258, cur:    0.212)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NetflixRecommender</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>0.130007</td>\n",
       "      <td>0.177868</td>\n",
       "      <td>0.254582</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>0.095015</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.139666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from recommenders.netflix_recommender import NetflixRecommender\n",
    "\n",
    "netflix_recommender = NetflixRecommender(embedding_dim=8, n_epochs=200, print_type='live')\n",
    "\n",
    "netflix_tts_results = [['NetflixRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    netflix_recommender, interactions_df, items_df))]\n",
    "\n",
    "netflix_tts_results = pd.DataFrame(\n",
    "    netflix_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(netflix_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "moderate-printing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNRecommender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmazonRecommender</td>\n",
       "      <td>0.046843</td>\n",
       "      <td>0.126273</td>\n",
       "      <td>0.173456</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.046843</td>\n",
       "      <td>0.092202</td>\n",
       "      <td>0.111853</td>\n",
       "      <td>0.135876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NetflixRecommender</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>0.130007</td>\n",
       "      <td>0.177868</td>\n",
       "      <td>0.254582</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>0.095015</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.139666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tts_results = pd.concat([nn_tts_results, amazon_tts_results, netflix_tts_results]).reset_index(drop=True)\n",
    "display(HTML(tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-vegetable",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Write a summary of your experiments. What worked well and what did not? What are your thoughts how could you possibly further improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "Niestety ten projekt za bardzo dokoczy tak mi si i nie udao. Przyznam si, e nie do koca wiem, dlaczego wyniki moje s tak\n",
    "ze, bo prbowaem zmienia liczb epok, liczb layers. A wychodzio tylko gorzej, na tyle, e scores wszendzie byo 0.0.\n",
    "W metodzie fit wida, e te prbowaem uywa modeli z embeddingami oraz matrix factorization z embeddings, tylko, e ten kod\n",
    "tak mi si i nie uruchomi(cigle bya gwiazdka w jupyter notebook). Dlatego przedstawiam tu jedyny model, w ktrym udao mi si\n",
    "uzyska chocia jaki wynik. I te parametry w NetworkModel daj najlepsze wyniki z moich kombinacji layers oraz liczby neuronw."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
